{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivampr21/.venv/clort/lib/python3.10/site-packages/torchvision-0.15.0a0+93df9a5-py3.10-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libnvjpeg.so.11: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from clort import ArgoCL\n",
    "from clort import ArgoCl_collate_fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../../../datasets/argoverse-tracking/argov1_proc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ArgoCL(root, temporal_horizon=1, temporal_overlap=0, distance_threshold=(0, 100), splits=['train4'], img_size=(224, 224),\n",
    "                  point_cloud_size=[20], in_global_frame=True, pivot_to_first_frame=True, image=True, pcl=True, bbox=True)\n",
    "# [20, 50, 100, 250, 500, 1000, 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcls, pcls_sz, imgs, imgs_sz, bboxs, track_idxs, cls_idxs, frame_sz = dataset[0]\n",
    "dl = DataLoader(dataset, batch_size=1, collate_fn=ArgoCl_collate_fxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_it = iter(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcls, pcls_sz, imgs, imgs_sz, bboxs, track_idxs, cls_idxs, frame_sz, sample_sz = next(dl_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from clort.model.encoders import MultiViewEncoder, PointCloudEncoder, MultiModalEncoder, CrossObjectEncoder\n",
    "from timm import create_model\n",
    "from torchviz import make_dot\n",
    "from torchview import draw_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 8, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_enc = MultiViewEncoder(out_dim=256).to('cuda:0')\n",
    "pc_enc = PointCloudEncoder(out_dims=128).to('cuda:0')\n",
    "mm_enc = MultiModalEncoder(mv_in_dim=256, pc_in_dim=128, out_dim=256).to('cuda:0')\n",
    "cr_enc = CrossObjectEncoder(256, 128).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs.to('cuda:0')\n",
    "pcls = pcls.to('cuda:0')\n",
    "bboxs = bboxs.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv_e.shape = torch.Size([13, 256])\n"
     ]
    }
   ],
   "source": [
    "mv_e = mv_enc(imgs, imgs_sz)\n",
    "print(f'{mv_e.shape = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pc_e.shape = torch.Size([13, 128])\n"
     ]
    }
   ],
   "source": [
    "pc_e = pc_enc(pcls, pcls_sz, bboxs)\n",
    "print(f'{pc_e.shape = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mm_e.shape = torch.Size([13, 256])\n"
     ]
    }
   ],
   "source": [
    "mm_e = mm_enc(mv_e, pc_e)\n",
    "print(f'{mm_e.shape = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cr_e.shape = torch.Size([13, 128])\n"
     ]
    }
   ],
   "source": [
    "cr_e = cr_enc(mm_e, frame_sz)\n",
    "print(f'{cr_e.shape = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clort import MemoryBank, MemoryBankInfer\n",
    "from clort.model.ContrastiveLoss import ContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = MemoryBank(dataset.n_tracks, 128, Q=5, alpha=torch.arange(1, 6, dtype=torch.float32).flip([0])/10, device=torch.device('cuda:0'))\n",
    "mbinfer = MemoryBankInfer(dataset.n_tracks, 128, Q=5, t=3, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = ContrastiveLoss(static_contrast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = cl(cr_e, torch.tensor(track_idxs.astype(int), dtype=torch.int32), mb.get_memory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.357988119125366"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.detach().cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "914"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb.update(cr_e.detach(), torch.tensor(track_idxs.tolist(), dtype=torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbinfer.update(torch.rand(cr_e.size(), device='cuda:0'), torch.tensor(track_idxs.tolist(), dtype=torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0337,  0.0940,  0.0266,  ...,  0.0828,  0.1607,  0.0054],\n",
       "         [ 0.0415,  0.1009,  0.0382,  ...,  0.0892,  0.1592,  0.0118],\n",
       "         [ 0.0482,  0.1035,  0.0466,  ...,  0.0939,  0.1554,  0.0181],\n",
       "         [ 0.0447,  0.0980,  0.0382,  ...,  0.0909,  0.1573,  0.0152],\n",
       "         [ 0.0313,  0.0907,  0.0220,  ...,  0.0800,  0.1601,  0.0035]],\n",
       "\n",
       "        [[ 0.0429,  0.1678, -0.0163,  ...,  0.0904,  0.0695,  0.1069],\n",
       "         [ 0.0568,  0.1603, -0.0105,  ...,  0.0965,  0.0705,  0.1139],\n",
       "         [ 0.0651,  0.1550, -0.0049,  ...,  0.0972,  0.0712,  0.1164],\n",
       "         [ 0.0538,  0.1651, -0.0080,  ...,  0.0908,  0.0721,  0.1109],\n",
       "         [ 0.0363,  0.1703, -0.0187,  ...,  0.0869,  0.0686,  0.1030]],\n",
       "\n",
       "        [[ 0.0597,  0.1504, -0.0457,  ...,  0.1107, -0.0049,  0.0235],\n",
       "         [ 0.0754,  0.1570, -0.0240,  ...,  0.1210,  0.0071,  0.0320],\n",
       "         [ 0.0872,  0.1602, -0.0078,  ...,  0.1265,  0.0175,  0.0392],\n",
       "         [ 0.0768,  0.1576, -0.0253,  ...,  0.1192,  0.0100,  0.0342],\n",
       "         [ 0.0537,  0.1476, -0.0536,  ...,  0.1062, -0.0089,  0.0203]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0571,  0.0752, -0.0358,  ...,  0.0372, -0.0663, -0.0057],\n",
       "         [ 0.0749,  0.0736, -0.0218,  ...,  0.0435, -0.0478,  0.0023],\n",
       "         [ 0.0880,  0.0717, -0.0103,  ...,  0.0473, -0.0333,  0.0092],\n",
       "         [ 0.0762,  0.0740, -0.0201,  ...,  0.0422, -0.0486,  0.0042],\n",
       "         [ 0.0503,  0.0754, -0.0404,  ...,  0.0343, -0.0732, -0.0085]],\n",
       "\n",
       "        [[ 0.0642,  0.0230,  0.0204,  ...,  0.0375, -0.0098,  0.0335],\n",
       "         [ 0.0655,  0.0304,  0.0363,  ...,  0.0478,  0.0082,  0.0504],\n",
       "         [ 0.0663,  0.0351,  0.0472,  ...,  0.0563,  0.0204,  0.0609],\n",
       "         [ 0.0666,  0.0293,  0.0348,  ...,  0.0510,  0.0055,  0.0467],\n",
       "         [ 0.0633,  0.0196,  0.0131,  ...,  0.0332, -0.0178,  0.0256]],\n",
       "\n",
       "        [[ 0.0887,  0.1453, -0.0493,  ...,  0.0564, -0.0070,  0.0417],\n",
       "         [ 0.0876,  0.1404, -0.0347,  ...,  0.0609,  0.0053,  0.0477],\n",
       "         [ 0.0871,  0.1365, -0.0213,  ...,  0.0635,  0.0146,  0.0526],\n",
       "         [ 0.0907,  0.1433, -0.0301,  ...,  0.0617,  0.0054,  0.0503],\n",
       "         [ 0.0888,  0.1465, -0.0555,  ...,  0.0544, -0.0128,  0.0389]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbinfer.get_reprs(torch.from_numpy(track_idxs.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0259,  0.0561, -0.0279,  ...,  0.0289,  0.1386, -0.0400],\n",
       "        [-0.0178,  0.1298, -0.0530,  ...,  0.0674,  0.0366,  0.0619],\n",
       "        [-0.0264,  0.0831, -0.1193,  ...,  0.0494, -0.0678, -0.0252],\n",
       "        ...,\n",
       "        [-0.0393,  0.0615, -0.0967,  ...,  0.0097, -0.1211, -0.0463],\n",
       "        [ 0.0349, -0.0104, -0.0475,  ..., -0.0390, -0.0741, -0.0316],\n",
       "        [ 0.0489,  0.1094, -0.1338,  ...,  0.0071, -0.0629, -0.0189]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(e):\n",
    "    e = e*2.\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = perturb(cr_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_e == a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'out.pdf'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(pc_e).render('./out')\n",
    "# # # model_graph = draw_graph(sv_enc, input_size=imgs.shape, expand_nested=False)\n",
    "# # tuple(mv_e.size())\n",
    "# mb.get_reprs(torch.tensor(track_idxs.tolist(), dtype=torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = draw_graph(pc_enc, input_data=(pcls, pcls_sz, bboxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = make_dot(s, params=dict(mv_enc.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'out.pdf'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.render('./out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = nn.AdaptiveMaxPool2d((1, 1))(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([123, 3, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([123, 512, 7, 7])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = imgs[0, :, :, :].permute(1, 2, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
